{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BagofWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bagofWord(corpus):\n",
    "    vocabulary = np.unique(' '.join(corpus).lower().split())\n",
    "  \n",
    "    doc_vectors = []\n",
    "    for doc in corpus:\n",
    "        doc_tuple = {}\n",
    "        for word in vocabulary:\n",
    "            if word not in doc_tuple:\n",
    "                doc_tuple[word] = 0\n",
    "\n",
    "        for word in doc.lower().split():\n",
    "            if word in vocabulary:\n",
    "                doc_tuple[word]+=1\n",
    "        doc_vectors.append(doc_tuple)\n",
    "\n",
    "    print(vocabulary)\n",
    "    for i, doc_vector in enumerate(doc_vectors):\n",
    "        print(corpus[i], list(doc_vector.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'hat' 'in' 'sat' 'the' 'with']\n",
      "the cat sat [1, 0, 0, 1, 1, 0]\n",
      "the cat sat in the hat [1, 1, 1, 1, 2, 0]\n",
      "the cat with the hat [1, 1, 0, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "bagofWord([\n",
    "  'the cat sat',\n",
    "  'the cat sat in the hat',\n",
    "  'the cat with the hat',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " array(['a', 'berlin', 'capital', 'france', 'germany', 'he', 'is', 'king',\n",
       "        'man', 'paris', 'poland', 'queen', 'she', 'warsaw', 'woman'],\n",
       "       dtype='<U7'))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.unique(' '.join(corpus).lower().split())\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "vocabulary_size, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a',\n",
       " 1: 'berlin',\n",
       " 2: 'capital',\n",
       " 3: 'france',\n",
       " 4: 'germany',\n",
       " 5: 'he',\n",
       " 6: 'is',\n",
       " 7: 'king',\n",
       " 8: 'man',\n",
       " 9: 'paris',\n",
       " 10: 'poland',\n",
       " 11: 'queen',\n",
       " 12: 'she',\n",
       " 13: 'warsaw',\n",
       " 14: 'woman'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx = { w: i for i, w in enumerate(vocabulary) }\n",
    "\n",
    "idx_word = { i: w for i, w in enumerate(vocabulary) }\n",
    "\n",
    "idx_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair\n",
    "window_size = 2\n",
    "arr_idx = []\n",
    "arr_word = []\n",
    "\n",
    "for doc in corpus:\n",
    "    word_per_doc = doc.split()\n",
    "    for idx, w in enumerate(word_per_doc):\n",
    "        for i in range(-window_size, window_size+1):\n",
    "            neighbour_idx = idx + i\n",
    "                \n",
    "            if neighbour_idx == idx or neighbour_idx < 0 or neighbour_idx >= len(word_per_doc):\n",
    "                continue\n",
    "        \n",
    "            neighbour_idx = min(len(word_per_doc) - 1, max(0, idx + i))\n",
    "            \n",
    "            arr_idx.append((word_idx[w], word_idx[ word_per_doc[neighbour_idx] ]))\n",
    "            arr_word.append((w, word_per_doc[neighbour_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('he', 'is'), (5, 6))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_word[0], arr_idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInput(word_idx, dtype=torch.float):\n",
    "    x = torch.zeros(vocabulary_size, dtype=dtype)\n",
    "    x[word_idx] = 1\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'berlin', 'capital', 'france', 'germany', 'he', 'is', 'king',\n",
       "       'man', 'paris', 'poland', 'queen', 'she', 'warsaw', 'woman'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getInput(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch at 0: 4.775860179322106\n",
      "epoch at 10: 4.159932239992278\n",
      "epoch at 20: 3.778918784005301\n",
      "epoch at 30: 3.5125010077442442\n",
      "epoch at 40: 3.3135516132627214\n",
      "epoch at 50: 3.159255078009197\n",
      "epoch at 60: 3.0368846314293996\n",
      "epoch at 70: 2.938060017142977\n",
      "epoch at 80: 2.8563636686120715\n",
      "epoch at 90: 2.7868152767419816\n"
     ]
    }
   ],
   "source": [
    "# the first hidden layer Count(Vpcabulary) by Count(Embedding)\n",
    "embedding_size = 5\n",
    "W1 = torch.randn((vocabulary_size, embedding_size), dtype=torch.float, requires_grad=True)\n",
    "W2 = torch.randn((embedding_size, vocabulary_size), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "num_epoch=100\n",
    "lr=0.001\n",
    "for epoch in range(num_epoch):\n",
    "    loss_val = 0\n",
    "    for x_idx, y_idx in arr_idx:\n",
    "        x = getInput(x_idx)\n",
    "        y = torch.tensor([y_idx], dtype=torch.long)\n",
    "\n",
    "        z1 = x @ W1\n",
    "        a2 = z1 @ W2\n",
    "        \n",
    "        log_softmax = F.log_softmax(a2, dim=0)\n",
    "        loss = F.nll_loss(log_softmax.reshape(1, -1), y)\n",
    "        loss_val += loss.data.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        W1.data -= lr * W1.grad.data\n",
    "        W2.data -= lr * W2.grad.data\n",
    "\n",
    "        W1.grad=None\n",
    "        W2.grad=None\n",
    "        \n",
    "    if epoch % 10 == 0: \n",
    "        print(f'epoch at {epoch}: {loss_val/len(arr_idx)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

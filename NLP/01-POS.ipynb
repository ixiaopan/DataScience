{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Treebank tagged sentences\n",
    "nlkt_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlkt_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_set,test_set = train_test_split(nlkt_data, train_size=.8, test_size=.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten data\n",
    "train_words_tag_set = [ t for segm in train_set for t in segm ]\n",
    "\n",
    "test_words_tag_set = [ t for segm in test_set for t in segm ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80351"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_words_tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_words_tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sumitomo', 'NOUN'), ('Metal', 'NOUN'), ('Mining', 'NOUN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words_tag_set[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to numpy array for easy computation\n",
    "s_train_words_tag_set = np.array(train_words_tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " array(['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON',\n",
       "        'PRT', 'VERB', 'X'], dtype='<U24'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique tags\n",
    "pos_tags = np.unique(s_train_words_tag_set[:, 1])\n",
    "\n",
    "len(pos_tags), pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80351, array(['Sumitomo', 'Metal', 'Mining'], dtype='<U24'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = s_train_words_tag_set[:,0]\n",
    "\n",
    "# vocabulary\n",
    "len(vocabulary), vocabulary[: 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(z_n|z_{n-1}) = \\frac{Count(z_n, z_{n-1})}{Count(z_{n-1})} \n",
    "\\\\\n",
    "p(x|z_n) = \\frac{Count(z_n, x)}{Count(z_{n})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z2_given_z1(z2, z1, table):    \n",
    "    \"\"\"\n",
    "    table: [(word, tag)]\n",
    "    \"\"\"\n",
    "    tags = table[:, 1]\n",
    "    len_z1 = (tags == z1).sum()\n",
    "    len_z2_z1 = 0\n",
    "    for i in range(len(tags) - 1):\n",
    "        if tags[i] == z1 and tags[i+1] == z2:\n",
    "            len_z2_z1 += 1\n",
    "    \n",
    "    return len_z2_z1 / len_z1\n",
    "\n",
    "\n",
    "def word_given_state(word, z1, table):\n",
    "    tags = table[:, 1]\n",
    "    len_z1 = (tags == z1).sum()\n",
    "\n",
    "    z1_table = table[tags == z1]\n",
    "    len_word = (z1_table[:, 0] == word).sum()\n",
    "    \n",
    "    return len_word / len_z1\n",
    "\n",
    "\n",
    "## transition matrix\n",
    "def create_transition_matrix(word_tag_table, tag_list):\n",
    "    matrix = np.zeros((len(tag_list), len(tag_list)))\n",
    "\n",
    "    for i, z_1 in enumerate(tag_list):\n",
    "        for j, z_2 in enumerate(tag_list):\n",
    "            matrix[i, j] = z2_given_z1(z_2, z_1, word_tag_table)\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vibiterbi(words, pos_tags, transition_matrix, word_tag_table):\n",
    "    T = len(words) # the length of the observations\n",
    "    N = len(pos_tags) # the length of the state\n",
    "\n",
    "    prob_matrix = np.zeros((N, T))\n",
    "    backpointer = np.zeros((N, T), dtype=int)\n",
    "\n",
    "    # initilization state\n",
    "    backpointer[:, 0] = 0\n",
    "\n",
    "    for word_index in range(T): # for each word\n",
    "        for state_index in range(N): # for each state \n",
    "            z_2 = pos_tags[state_index]\n",
    "            emission_prob = word_given_state(words[word_index], z_2, word_tag_table)\n",
    "            \n",
    "            # initilization state\n",
    "            if word_index == 0:\n",
    "                transition_prob = transition_matrix.loc['.', z_2]\n",
    "                prob_matrix[state_index, word_index] = transition_prob * emission_prob\n",
    "            else:\n",
    "                p = []\n",
    "                z1_prob_list = prob_matrix[:, word_index - 1] # N state probability\n",
    "                for z1_index, z1_prob in enumerate(z1_prob_list):\n",
    "                    p.append(z1_prob * transition_matrix.loc[pos_tags[z1_index], z_2] * emission_prob)\n",
    "\n",
    "                max_prob = max(p)\n",
    "                max_prob_index = np.argmax(p)\n",
    "\n",
    "                prob_matrix[state_index, word_index] = max_prob\n",
    "                backpointer[state_index, word_index] = max_prob_index\n",
    "\n",
    "    bestprob = np.max(prob_matrix[:,-1])\n",
    "    bestpointer = np.argmax(prob_matrix[:,-1])\n",
    "\n",
    "    bestpath = []\n",
    "    for i in range(T): \n",
    "        bestpath.append(pos_tags[bestpointer])\n",
    "        bestpointer = backpointer[bestpointer, -1 - i]\n",
    "\n",
    "    return bestprob, bestpath[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = create_transition_matrix(s_train_words_tag_set, pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transition_matrix = pd.DataFrame(transition_matrix, columns=pos_tags, index=pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " '.',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'VERB']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = \"Peter is a young man , A company market is raising\"\n",
    "\n",
    "_, test_tags = Vibiterbi(test_sent.split(), pos_tags, df_transition_matrix, s_train_words_tag_set)\n",
    "\n",
    "test_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test_words_tag_set = np.array(test_words_tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = s_test_words_tag_set[:, 1][:29]\n",
    "\n",
    "X_test = s_test_words_tag_set[:, 0][:29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_hat = Vibiterbi(X_test, pos_tags, df_transition_matrix, s_train_words_tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy: If the test words are not in the vocabulary, the accuracy is very low.\n",
    "np.sum(y_hat == y_test) / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

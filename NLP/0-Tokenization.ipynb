{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/inaugural.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('inaugural')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fellow-Citizens of the Senate and of the House of Representatives:\n",
      "\n",
      "Among the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was transmitted by your order, and received on the 14th day of the present month. On the one hand, I was summoned by my Country, whose voice I can never hear but with veneration and love, from a retreat which I had chosen with the fondest predilection, and, in my flattering hopes, with an immutable decision, as the asylum of my declining years -- a retreat which was rendered every day more necessary as well as more dear to me by the addition of habit to inclination, and of frequent interruptions in my health to the gradual waste committed on it by time. On the other hand, the magnitude and difficulty of the trust to which the voice of my country called me, being sufficient to awaken in the wisest and most experienced of her citizens a distrustful scrutiny into his qualifications, could not bu\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "\n",
    "corpus = inaugural.raw('1789-Washington.txt')\n",
    "\n",
    "print(corpus[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_token = word_tokenize(corpus)\n",
    "\n",
    "len(words_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_token = sent_tokenize(corpus)\n",
    "\n",
    "len(sentence_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(words_token)\n",
    "\n",
    "len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "runner-->runner\n",
      "running-->run\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fairli\n",
      "saw-->saw\n"
     ]
    }
   ],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly', 'saw']\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word + '-->' + p_stemmer.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n",
      "saw --> saw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "for w in words:\n",
    "    print(w + ' --> ' + s_stemmer.stem(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemSentence(sentence, stemming):\n",
    "    words_token = word_tokenize(sentence)\n",
    "\n",
    "    stemmed_word_list = []\n",
    "    for word in words_token:\n",
    "        stemmed_word_list.append(stemming.stem(word))\n",
    "\n",
    "    return ' '.join(stemmed_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairli , On the eve of her wed , a young queen set out to rescu a princess from an enchant . she cast asid her fine wed cloth , take her chain mail and her sword and follow her brave dwarf retain into the tunnel under the mountain toward the sleep kingdom .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemSentence(\n",
    "    'fairly, On the eve of her wedding, a young queen sets out to rescue a princess from an enchantment. She casts aside her fine wedding clothes, takes her chain mail and her sword and follows her brave dwarf retainers into the tunnels under the mountain towards the sleeping kingdom. ',\n",
    "    p_stemmer\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair , on the eve of her wed , a young queen set out to rescu a princess from an enchant . she cast asid her fine wed cloth , take her chain mail and her sword and follow her brave dwarf retain into the tunnel under the mountain toward the sleep kingdom .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemSentence(\n",
    "    'fairly, On the eve of her wedding, a young queen sets out to rescue a princess from an enchantment. She casts aside her fine wedding clothes, takes her chain mail and her sword and follows her brave dwarf retainers into the tunnels under the mountain towards the sleeping kingdom. ',\n",
    "    s_stemmer\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grows',\n",
       " 'leaf',\n",
       " 'fairly',\n",
       " 'cat',\n",
       " 'trouble',\n",
       " 'running',\n",
       " 'friendship',\n",
       " 'easily',\n",
       " 'wa',\n",
       " 'relational',\n",
       " 'ha']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"grows\",\"leaves\",\"fairly\",\"cats\",\"trouble\",\"running\",\"friendships\",\"easily\", \"was\", \"relational\",\"has\"]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_words = [ lemmatizer.lemmatize(w) for w in words ]\n",
    "\n",
    "lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grow',\n",
       " 'leave',\n",
       " 'fairly',\n",
       " 'cat',\n",
       " 'trouble',\n",
       " 'run',\n",
       " 'friendships',\n",
       " 'easily',\n",
       " 'be',\n",
       " 'relational',\n",
       " 'have']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_words = [ lemmatizer.lemmatize(w, pos='v') for w in words ]\n",
    "lemma_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeSentence(sentence):\n",
    "    words_token = word_tokenize(sentence)\n",
    "\n",
    "    lemmatized_word_list = []\n",
    "    for word in words_token:\n",
    "        lemmatized_word_list.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    return ' '.join(lemmatized_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairly , On the eve of her wedding , a young queen set out to rescue a princess from an enchantment . She cast aside her fine wedding clothes , take her chain mail and her sword and follows her brave dwarf retainer into the tunnel under the mountain towards the sleeping kingdom .'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizeSentence('fairly, On the eve of her wedding, a young queen sets out to rescue a princess from an enchantment. She casts aside her fine wedding clothes, takes her chain mail and her sword and follows her brave dwarf retainers into the tunnels under the mountain towards the sleeping kingdom. ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/wuxiaopan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reuters_model():\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for sentence in reuters.sents():\n",
    "        # counts\n",
    "        for w1, w2, w3 in trigrams(sentence):\n",
    "            model[(w1, w2)][w3] += 1\n",
    "\n",
    "    # convert it to the probability\n",
    "    for w1_w2 in model.keys():\n",
    "        length = sum(model[w1_w2].values())\n",
    "        for w3 in model[w1_w2].keys():\n",
    "            model[w1_w2][w3] /= length\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_reuters_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['public', 'European', 'Bank', 'price', 'emirate', 'overseas', 'newspaper', 'company', 'Turkish', 'increase', 'options', 'Higher', 'pound', 'Italian', 'time'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[('today', 'the')].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is essential if the Japan - to ensure we have so far produced results -- Lufeng 13 - 1 / 4 at 26 degrees ( fahrenheit ),\" Krenzler said . Basically , their cash credits dropped 400 mln dlrs . s . energy futures , the officials said the modernization would involve an exchange spokeswoman said the authorities would have to be competitive .'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def auto_generate_text():\n",
    "    start_text = ['It', 'is']\n",
    "\n",
    "    for i in range(100):\n",
    "        p = random.random()\n",
    "        accumulator = 0\n",
    "\n",
    "        w1_w2 = tuple(start_text[-2:])\n",
    "        for w3 in model[w1_w2].keys():\n",
    "            accumulator += model[w1_w2][w3]\n",
    "    \n",
    "            if accumulator >= p:\n",
    "                start_text.append(w3)\n",
    "                break\n",
    "\n",
    "    return ' '.join(start_text)\n",
    "            \n",
    "    \n",
    "auto_generate_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
